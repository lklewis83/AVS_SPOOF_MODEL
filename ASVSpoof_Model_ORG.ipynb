{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "k_ue25LodfLC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.18.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf  # For handling FLAC & WAV files\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras import backend as K\n",
    "\n",
    "# Suppress warnings\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            features     label\n",
      "0  [-337.1201, 61.995434, -2.45123, 19.191284, 1....  bonafide\n",
      "1  [-342.31143, 44.619663, -6.771269, 9.524557, -...  bonafide\n",
      "2  [-369.46967, 43.674416, -1.1685817, 26.372791,...  bonafide\n",
      "3  [-296.1914, 46.492588, -5.0006576, 19.09601, -...  bonafide\n",
      "4  [-328.49338, 60.683876, 1.5566636, 15.033571, ...  bonafide\n"
     ]
    }
   ],
   "source": [
    "# TIME INTENSIVE\n",
    "\n",
    "\n",
    "# Define correct paths\n",
    "#base_dir = \"./AVSSpoof/LA/LA/ASVspoof2019_LA_train/flac\"  # Already points to 'flac'\n",
    "base_dir = \"./AVSSpoof/LA/LA/ASVspoof2019_LA_dev/flac\" \n",
    "dataset_dir = \"./AVSSpoof/LA/LA\"\n",
    "#protocol_file = os.path.join(dataset_dir, \"ASVspoof2019_LA_cm_protocols\", \"ASVspoof2019.LA.cm.train.trn.txt\")\n",
    "protocol_file = os.path.join(dataset_dir, \"ASVspoof2019_LA_cm_protocols\", \"ASVspoof2019.LA.cm.dev.trl.txt\")\n",
    "\n",
    "# Ensure file exists before running\n",
    "if not os.path.exists(protocol_file):\n",
    "    raise FileNotFoundError(f\"Protocol file not found: {protocol_file}\")\n",
    "\n",
    "# Feature extraction functions\n",
    "def extract_mfcc(file_path, n_mfcc=128):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    #print(mfcc.shape)\n",
    "    return np.mean(mfcc.T, axis=0)  # Mean aggregation over time\n",
    "\n",
    "def extract_mfsc(file_path, n_mels=128, n_fft=2048, hop_length=512):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mfsc = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length)\n",
    "    #print(mfsc.shape)\n",
    "    return np.mean(mfsc.T, axis=0)  # Mean aggregation over time\n",
    "\n",
    "# Load metadata and extract features\n",
    "def load_data(protocol_file, base_dir):\n",
    "    data = []\n",
    "    with open(protocol_file, 'r') as f:\n",
    "        for line in f:\n",
    "            tokens = line.strip().split()\n",
    "            \n",
    "            # Ensure valid tokens before proceeding\n",
    "            if len(tokens) < 2:\n",
    "                print(f\"Skipping malformed line: {line.strip()}\")\n",
    "                continue\n",
    "\n",
    "            file_id, label = tokens[1], tokens[-1]\n",
    "\n",
    "            # FIX: Do NOT add 'flac' again since base_dir already includes it\n",
    "            file_path = os.path.join(base_dir, file_id + \".flac\")\n",
    "\n",
    "            # Check if the file actually exists\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"Warning: File not found - {file_path}\")\n",
    "                continue\n",
    "\n",
    "            features = extract_mfcc(file_path)\n",
    "            data.append((features, label))\n",
    "\n",
    "    return pd.DataFrame(data, columns=[\"features\", \"label\"])\n",
    "\n",
    "# Load training data\n",
    "train_data = load_data(protocol_file, base_dir)\n",
    "\n",
    "# Print results\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Metrics for Binary Classification\"\n",
    "output: html_document\n",
    "---\n",
    "\n",
    "## Precision\n",
    "Measures how many of the positively predicted cases were actually positive.\n",
    "\n",
    "**Related to Type 1 Error (False Positives):**  \n",
    "A lower precision indicates a higher Type 1 error rate.\n",
    "\n",
    "---\n",
    "\n",
    "## Recall (Sensitivity)\n",
    "Measures how many actual positives were correctly predicted.\n",
    "\n",
    "**Related to Type 2 Error (False Negatives):**  \n",
    "A lower recall indicates a higher Type 2 error rate.\n",
    "\n",
    "---\n",
    "\n",
    "## Specificity\n",
    "Measures how many actual negatives were correctly predicted.\n",
    "\n",
    "\n",
    "**Relationship to Type 1 Error:**  \n",
    "Type 1 error is directly measured as:\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x Shape: (24844, 128)\n",
      "y Shape: (24844,)\n",
      "x_array Shape: (24844, 128)\n",
      "y_array Shape: (24844,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and labels\n",
    "y = []\n",
    "\n",
    "X = np.array(train_data[\"features\"].tolist())\n",
    "y = LabelEncoder().fit_transform(train_data[\"label\"])\n",
    "print(\"x Shape:\", X.shape) \n",
    "print(\"y Shape:\", y.shape)  \n",
    "\n",
    "# Random 80/20 split\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Cross Validation\n",
    "x_array = X\n",
    "y_array = np.array(y)\n",
    "\n",
    "print(\"x_array Shape:\", x_array.shape) \n",
    "print(\"y_array Shape:\", y_array.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for numpy (used in data preprocessing)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the seed for Python's built-in random module (used in shuffling, etc.)\n",
    "random.seed(42)\n",
    "\n",
    "# Set the TensorFlow seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Ensure deterministic operations in TensorFlow (useful for GPU operations)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "os.environ['PYTHONHASHSEED'] = '42'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YLHWyMUOd0tp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 18:33:43.148126: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-02-06 18:34:47.138904: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Final Cross-Validation Results:**\n",
      "Fold 1 | Accuracy: 0.9992, Precision: 0.9996, Recall: 0.9996, AUC: 1.0000\n",
      "Training Fold 2/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 18:37:54.485996: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Final Cross-Validation Results:**\n",
      "Fold 2 | Accuracy: 0.9988, Precision: 0.9987, Recall: 1.0000, AUC: 1.0000\n",
      "Training Fold 3/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 18:39:46.553769: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Final Cross-Validation Results:**\n",
      "Fold 3 | Accuracy: 0.9984, Precision: 0.9996, Recall: 0.9987, AUC: 1.0000\n",
      "Training Fold 4/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 18:41:32.017082: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Final Cross-Validation Results:**\n",
      "Fold 4 | Accuracy: 0.9992, Precision: 0.9991, Recall: 1.0000, AUC: 1.0000\n",
      "Training Fold 5/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 18:43:54.726853: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Final Cross-Validation Results:**\n",
      "Fold 5 | Accuracy: 0.9988, Precision: 1.0000, Recall: 0.9986, AUC: 1.0000\n",
      "Training Fold 6/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 18:45:41.366145: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Final Cross-Validation Results:**\n",
      "Fold 6 | Accuracy: 0.9988, Precision: 0.9991, Recall: 0.9995, AUC: 0.9995\n",
      "Training Fold 7/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 18:48:02.907987: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Final Cross-Validation Results:**\n",
      "Fold 7 | Accuracy: 0.9992, Precision: 1.0000, Recall: 0.9991, AUC: 1.0000\n",
      "Training Fold 8/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 18:50:52.182444: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Final Cross-Validation Results:**\n",
      "Fold 8 | Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, AUC: 1.0000\n",
      "Training Fold 9/10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 18:52:24.507479: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Final Cross-Validation Results:**\n",
      "Fold 9 | Accuracy: 0.9891, Precision: 1.0000, Recall: 0.9879, AUC: 1.0000\n",
      "Training Fold 10/10...\n",
      "\n",
      " **Final Cross-Validation Results:**\n",
      "Fold 10 | Accuracy: 0.9996, Precision: 0.9996, Recall: 1.0000, AUC: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 18:53:23.133835: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "           \n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "auc_scores = []   \n",
    "\n",
    "results = []\n",
    "best_auc = 0\n",
    "best_model = None\n",
    "best_settings = {}\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)  # Reduce from default 0.001\n",
    "\n",
    "# Keras Log Capture\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# CROSS VALIDATION | K FOLDS\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(x_array)):\n",
    "    print(f\"Training Fold {fold+1}/{k}...\")\n",
    "\n",
    "    x_train, x_val = x_array[train_idx], x_array[val_idx]\n",
    "    y_train, y_val = y_array[train_idx], y_array[val_idx]\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    x_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "    # Build the model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(x_train.shape[1],)),  # Define input shape here\n",
    "        tf.keras.layers.Dense(200, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.1), # ORG .3\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        #tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', \n",
    "    #model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', \n",
    "                           Precision(name='precision'), \n",
    "                           Recall(name='recall'), \n",
    "                           AUC(curve='PR', name='auc_pr')])  # PR AUC is related to F1 Score\n",
    "\n",
    "    #history = model.fit(x_train, y_train, validation_data=(x_val, y_val),verbose=0, epochs=100, batch_size=32, callbacks=[early_stopping])\n",
    "    history = model.fit(x_train_resampled, y_train_resampled, validation_data=(x_val, y_val),verbose=0, epochs=100, batch_size=32, callbacks=[early_stopping])\n",
    "\n",
    "    scores = model.evaluate(x_val, y_val, verbose=0)\n",
    "    accuracy, precision, recall, auc = scores[1],scores[2],scores[3],scores[4]\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    auc_scores.append(auc)\n",
    "    #Compute average metrics\n",
    "    print(\"\\n **Final Cross-Validation Results:**\")\n",
    "    #print(f\"Average Accuracy: {np.mean(accuracy_scores):.4f}\")\n",
    "    #print(f\"Average Precision: {np.mean(precision_scores):.4f}\")\n",
    "    #print(f\"Average Recall: {np.mean(recall_scores):.4f}\")\n",
    "    #print(f\"Average AUC: {np.mean(auc_scores):.4f}\")\n",
    "    #print(\"-------------------------------------------\")\n",
    "\n",
    "    # SAVE BEST MODEL\n",
    "    results.append({\n",
    "        \"fold\": fold+1,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"auc\": auc})\n",
    "    print(f\"Fold {fold+1} | Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, AUC: {auc:.4f}\")\n",
    "\n",
    "    if auc > best_auc:\n",
    "        best_auc = auc\n",
    "        best_model = model\n",
    "        best_settings = {            \n",
    "            \"fold\": fold+1,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"auc\": auc,\n",
    "            \"layers\":[200,128,64],\n",
    "            \"epochs\": 50,\n",
    "            \"batch_size\": 32,\n",
    "            \"optimizer\": \"adam\"}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(X_train, y_train, validation_data=(X_val, y_val),verbose=0, epochs=500, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best validation accuracy and loss\n",
    "#best_epoch = np.argmin(history.history['loss'])  # Get epoch with lowest validation loss\n",
    "#best_val_loss = history.history['loss'][best_epoch]\n",
    "#best_val_acc = history.history['accuracy'][best_epoch]\n",
    "#best_precision = history.history['precision'][best_epoch]\n",
    "#best_recall = history.history['recall'][best_epoch]\n",
    "#best_auc = history.history['auc_pr'][best_epoch]\n",
    "\n",
    "#print(f\"Best Epoch: {best_epoch+1}\")  # +1 because epochs start from 0\n",
    "#print(f\"Best Validation Loss: {best_val_loss:.4f}\")\n",
    "#print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n",
    "#print(f\"Best Precision: {best_precision:.4f}\")\n",
    "#print(f\"Best Recall: {best_recall:.4f}\")\n",
    "#print(f\"Best AUC: {best_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_results = {\n",
    "    \"avg_accuracy\": np.mean([r[\"accuracy\"] for r in results]),\n",
    "    \"avg_precision\": np.mean([r[\"precision\"] for r in results]),\n",
    "    \"avg_recall\": np.mean([r[\"recall\"] for r in results]),\n",
    "    \"avg_auc\": np.mean([r[\"auc\"] for r in results])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC\n",
    "Best Epoch: 39\n",
    "Best Validation Loss: 0.0088\n",
    "Best Validation Accuracy: 0.9969\n",
    "Best Precision: 0.9982\n",
    "Best Recall: 0.9984\n",
    "Best AUC: 0.9999\n",
    "\n",
    "# MFSC\n",
    "Best Epoch: 85\n",
    "Best Validation Loss: 0.1235\n",
    "Best Validation Accuracy: 0.9512\n",
    "Best Precision: 0.9635\n",
    "Best Recall: 0.9829\n",
    "Best AUC: 0.9960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ddwf5wFIecW7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Final Cross-Validation Results:**\n",
      "Best Model from Fold 4: AUC = 1.0000\n",
      "Average Accuracy: 0.9981\n",
      "Average Precision: 0.9996\n",
      "Average Recall: 0.9983\n",
      "Average AUC: 1.0000\n",
      "\n",
      "Best Model Settings: {'fold': 4, 'accuracy': 0.9991951584815979, 'precision': 0.9991079568862915, 'recall': 1.0, 'auc': 1.0, 'layers': [200, 128, 64], 'epochs': 50, 'batch_size': 32, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'model' is your trained model\n",
    "#model.save(\"./AVSSpoof/audio_spoofing_model.keras\")\n",
    "\n",
    "# Save best model\n",
    "best_model.save(\"./AVSSpoof/audio_spoofing_model.keras\")\n",
    "\n",
    "# Print final results\n",
    "print(\"\\n **Final Cross-Validation Results:**\")\n",
    "print(f\"Best Model from Fold {best_settings['fold']}: AUC = {best_auc:.4f}\")\n",
    "print(f\"Average Accuracy: {avg_results['avg_accuracy']:.4f}\")\n",
    "print(f\"Average Precision: {avg_results['avg_precision']:.4f}\")\n",
    "print(f\"Average Recall: {avg_results['avg_recall']:.4f}\")\n",
    "print(f\"Average AUC: {avg_results['avg_auc']:.4f}\")\n",
    "print(\"\\nBest Model Settings:\", best_settings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "%rm -rf logs/scalars/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
